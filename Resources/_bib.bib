@article{bulla_supporting_2025,
	title = {Supporting information for "{Replicaton} of “{Historical} redlining is associated with increasing geographical disparities in bird biodiversity sampling in the {United} {States}”},
	url = {https://martinbulla.github.io/I4R_Nat_Hum_Beh/},
	journal = {GitHub},
	author = {Bulla, Martin and Mikula, Peter},
	year = {2025},
	keywords = {code, data, replication, repository, supplement},
}

@article{bulla_supporting_2026,
	title = {Supporting information for "Data aggregation blurs inferred temporal trends in bird sampling"},
	url = {https://martinbulla.github.io/MA_NHB/},
	journal = {GitHub},
	author = {Bulla, Martin and Mikula, Peter},
	year = {2026},
	keywords = {code, data, replication, repository, supplement},
}

@article{bulla_MA_2026,
	title = {Data aggregation blurs inferred temporal trends in bird sampling},
	url = {https://doi.org/10.32942/X2NS9V},
	journal = {EcoEvoRxiv},
	author = {Bulla, Martin and Mikula, Peter},
	year = {2025},
	keywords = {code, data, replication, repository, supplement},
}

@article{bulla_replication_2025,
	title = {Replicaton of “{Historical} redlining is associated with increasing geographical disparities in bird biodiversity sampling in the {United} {States}”},
	url = {https://doi.org/10.32942/X2TQ09},
	journal = {EcoEvoRxiv},
	author = {Bulla, Martin and Mikula, Peter},
	year = {2025},
	keywords = {code, data, replication, repository, supplement},
}

@inbook{Akaike2025,
	author = {Akaike, Hirotugu},
	editor = {Lovric, Miodrag},
	title = {Akaike's Information Criterion},
	booktitle = {International Encyclopedia of Statistical Science},
	year = {2025},
	publisher = {Springer Berlin Heidelberg},
	address = {Berlin, Heidelberg},
	pages = {41--42},
	isbn = {978-3-662-69359-9},
	doi = {10.1007/978-3-662-69359-9_14},
	url = {https://doi.org/10.1007/978-3-662-69359-9_14}
}

@article{ellis-soto_historical_2023,
	author = {Ellis-Soto, Diego and Chapman, Melissa and Locke, Dexter H.},
	title = {Historical redlining is associated with increasing geographical disparities in bird biodiversity sampling in the {United} {States}},
	journal = {Nat Hum Behav},
	year = {2023},
	month = nov,
	volume = {7},
	number = {11},
	pages = {1869--1877},
	doi = {10.1038/s41562-023-01688-5},
	url = {https://www.nature.com/articles/s41562-023-01688-5},
	issn = {2397-3374},
	copyright = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
	abstract = {Historic segregation and inequality are critical to understanding modern environmental conditions. Race-based zoning policies, such as redlining in the United States during the 1930s, are associated with racial inequity and adverse multigenerational socioeconomic levels in income and education, and disparate environmental characteristics including tree canopy cover across urban neighbourhoods. Here we quantify the association between redlining and bird biodiversity sampling density and completeness—two critical metrics of biodiversity knowledge—across 195 cities in the United States. We show that historically redlined neighbourhoods remain the most undersampled urban areas for bird biodiversity today, potentially impacting conservation priorities and propagating urban environmental inequities. The disparity in sampling across redlined neighbourhood grades increased by 35.6\% over the past 20 years. We identify specific urban areas in need of increased bird biodiversity sampling and discuss possible strategies for reducing uncertainty and increasing equity of sampling of biodiversity in urban areas. Our findings highlight how human behaviour and past social, economic and political conditions not just segregate our built environment but may also leave a lasting mark on the digital information we have about urban biodiversity.},
	language = {en},
	urldate = {2025-08-25},
	note = {Publisher: Nature Publishing Group},
	keywords = {Urban ecology, Biodiversity, History, Social policy, Sustainability}
}

@article{verbyla2019,
	author = {Verbyla, Arunas Petras},
	title = {A note on model selection using information criteria for general linear models estimated using {REML}},
	journal = {Australian \& New Zealand Journal of Statistics},
	year = {2019},
	volume = {61},
	number = {1},
	pages = {39--50},
	doi = {10.1111/anzs.12254},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/anzs.12254},
	issn = {1467-842X},
	copyright = {© 2019 Australian Statistical Publishing Association Inc. Published by John Wiley \& Sons Australia Pty Ltd.},
	abstract = {It is common practice to compare the fit of non-nested models using the Akaike (AIC) or Bayesian (BIC) information criteria. The basis of these criteria is the log-likelihood evaluated at the maximum likelihood estimates of the unknown parameters. For the general linear model (and the linear mixed model, which is a special case), estimation is usually carried out using residual or restricted maximum likelihood (REML). However, for models with different fixed effects, the residual likelihoods are not comparable and hence information criteria based on the residual likelihood cannot be used. For model selection, it is often suggested that the models are refitted using maximum likelihood to enable the criteria to be used. The first aim of this paper is to highlight that both the AIC and BIC can be used for the general linear model by using the full log-likelihood evaluated at the REML estimates. The second aim is to provide a derivation of the criteria under REML estimation. This aim is achieved by noting that the full likelihood can be decomposed into a marginal (residual) and conditional likelihood and this decomposition then incorporates aspects of both the fixed effects and variance parameters. Using this decomposition, the appropriate information criteria for model selection of models which differ in their fixed effects specification can be derived. An example is presented to illustrate the results and code is available for analyses using the ASReml-R package.},
	language = {en},
	urldate = {2025-08-27},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/anzs.12254},
	keywords = {Akaike information criterion, Bayesian information criterion, residual maximum likelihood},
}

@article{forstmeier2011,
	author = {Forstmeier, Wolfgang and Schielzeth, Holger},
	title = {Cryptic multiple hypotheses testing in linear models: overestimated effect sizes and the winner's curse},
	journal = {Behavioral Ecology and Sociobiology},
	year = {2011},
	month = jan,
	volume = {65},
	number = {1},
	pages = {47--55},
	doi = {10.1007/s00265-010-1038-5},
	url = {https://doi.org/10.1007/s00265-010-1038-5},
	issn = {1432-0762},
	shorttitle = {Cryptic multiple hypotheses testing in linear models},
	abstract = {Fitting generalised linear models (GLMs) with more than one predictor has become the standard method of analysis in evolutionary and behavioural research. Often, GLMs are used for exploratory data analysis, where one starts with a complex full model including interaction terms and then simplifies by removing non-significant terms. While this approach can be useful, it is problematic if significant effects are interpreted as if they arose from a single a priori hypothesis test. This is because model selection involves cryptic multiple hypothesis testing, a fact that has only rarely been acknowledged or quantified. We show that the probability of finding at least one ‘significant’ effect is high, even if all null hypotheses are true (e.g. 40\% when starting with four predictors and their two-way interactions). This probability is close to theoretical expectations when the sample size (N) is large relative to the number of predictors including interactions (k). In contrast, type I error rates strongly exceed even those expectations when model simplification is applied to models that are over-fitted before simplification (low N/k ratio). The increase in false-positive results arises primarily from an overestimation of effect sizes among significant predictors, leading to upward-biased effect sizes that often cannot be reproduced in follow-up studies (‘the winner's curse’). Despite having their own problems, full model tests and P value adjustments can be used as a guide to how frequently type I errors arise by sampling variation alone. We favour the presentation of full models, since they best reflect the range of predictors investigated and ensure a balanced representation also of non-significant results.},
	language = {en},
	urldate = {2025-08-28},
	keywords = {Bonferroni correction, Effect size estimation, Generalised linear models, Model selection, Multiple regression, Multiple testing, Parameter estimation, Publication bias}
}

@article{whittingham2006,
	author = {Whittingham, Mark J. and Stephens, Philip A. and Bradbury, Richard B. and Freckleton, Robert P.},
	title = {Why do we still use stepwise modelling in ecology and behaviour?},
	journal = {Journal of Animal Ecology},
	year = {2006},
	volume = {75},
	number = {5},
	pages = {1182--1189},
	doi = {10.1111/j.1365-2656.2006.01141.x},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2656.2006.01141.x},
	issn = {1365-2656},
	abstract = {1 The biases and shortcomings of stepwise multiple regression are well established within the statistical literature. However, an examination of papers published in 2004 by three leading ecological and behavioural journals suggested that the use of this technique remains widespread: of 65 papers in which a multiple regression approach was used, 57\% of studies used a stepwise procedure. 2 The principal drawbacks of stepwise multiple regression include bias in parameter estimation, inconsistencies among model selection algorithms, an inherent (but often overlooked) problem of multiple hypothesis testing, and an inappropriate focus or reliance on a single best model. We discuss each of these issues with examples. 3 We use a worked example of data on yellowhammer distribution collected over 4 years to highlight the pitfalls of stepwise regression. We show that stepwise regression allows models containing significant predictors to be obtained from each year's data. In spite of the significance of the selected models, they vary substantially between years and suggest patterns that are at odds with those determined by analysing the full, 4-year data set. 4 An information theoretic (IT) analysis of the yellowhammer data set illustrates why the varying outcomes of stepwise analyses arise. In particular, the IT approach identifies large numbers of competing models that could describe the data equally well, showing that no one model should be relied upon for inference.},
	language = {en},
	urldate = {2025-08-28},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2656.2006.01141.x},
	keywords = {ecological modelling, habitat selection, minimum adequate model, multivariate statistical analysis, statistical bias}
}

@article{cade2015,
	author = {Cade, Brian S.},
	title = {Model averaging and muddled multimodel inferences},
	journal = {Ecology},
	year = {2015},
	volume = {96},
	number = {9},
	pages = {2370--2382},
	doi = {10.1890/14-1639.1},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1890/14-1639.1},
	issn = {1939-9170},
	copyright = {© 2015 by the Ecological Society of America},
	abstract = {Three flawed practices associated with model averaging coefficients for predictor variables in regression models commonly occur when making multimodel inferences in analyses of ecological data. Model-averaged regression coefficients based on Akaike information criterion (AIC) weights have been recommended for addressing model uncertainty but they are not valid, interpretable estimates of partial effects for individual predictors when there is multicollinearity among the predictor variables. Multicollinearity implies that the scaling of units in the denominators of the regression coefficients may change across models such that neither the parameters nor their estimates have common scales, therefore averaging them makes no sense. The associated sums of AIC model weights recommended to assess relative importance of individual predictors are really a measure of relative importance of models, with little information about contributions by individual predictors compared to other measures of relative importance based on effects size or variance reduction. Sometimes the model-averaged regression coefficients for predictor variables are incorrectly used to make model-averaged predictions of the response variable when the models are not linear in the parameters. I demonstrate the issues with the first two practices using the college grade point average example extensively analyzed by Burnham and Anderson. I show how partial standard deviations of the predictor variables can be used to detect changing scales of their estimates with multicollinearity. Standardizing estimates based on partial standard deviations for their variables can be used to make the scaling of the estimates commensurate across models, a necessary but not sufficient condition for model averaging of the estimates to be sensible. A unimodal distribution of estimates and valid interpretation of individual parameters are additional requisite conditions. The standardized estimates or equivalently the t statistics on unstandardized estimates also can be used to provide more informative measures of relative importance than sums of AIC weights. Finally, I illustrate how seriously compromised statistical interpretations and predictions can be for all three of these flawed practices by critiquing their use in a recent species distribution modeling technique developed for predicting Greater Sage-Grouse (Centrocercus urophasianus) distribution in Colorado, USA. These model averaging issues are common in other ecological literature and ought to be discontinued if we are to make effective scientific contributions to ecological knowledge and conservation of natural resources.},
	language = {en},
	urldate = {2025-08-28},
	note = {\_eprint: https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1890/14-1639.1},
	keywords = {generalized linear models, species distribution models, Greater Sage-Grouse, model averaging, multicollinearity, multimodel inference, partial effects, partial standard deviations, regression coefficients, relative importance of predictors, zero-truncated Poisson regression}
}

@incollection{bolker2015,
	author = {Bolker, Benjamin M.},
	title = {Linear and generalized linear mixed models},
	booktitle = {Ecological Statistics: Contemporary theory and application},
	editor = {Fox, Gordon A. and Negrete-Yankelevich, Simoneta and Sosa, Vinicio J.},
	year = {2015},
	month = jan,
	publisher = {Oxford University Press},
	pages = {0},
	doi = {10.1093/acprof:oso/9780199672547.003.0014},
	url = {https://doi.org/10.1093/acprof:oso/9780199672547.003.0014},
	isbn = {978-0-19-967254-7},
	abstract = {Generalized linear mixed models (GLMMs) are a powerful class of statistical models that combine the characteristics of generalized linear models and mixed models (models with both fixed and random predictor variables). This chapter: reviews the conceptual and theoretical background of GLMMs, focusing on the definition and meaning of random effects; gives basic guidelines and syntax for setting up a mixed model; and discusses the theoretical and practical details of estimating parameters, diagnosing problems with a model, and making statistical inferences (finding confidence intervals, estimating p values, and doing model selection) for GLMMs.},
	urldate = {2025-08-28}
}

@article{boettiger2015,
	author = {Boettiger, Carl},
	title = {An introduction to {Docker} for reproducible research},
	journal = {SIGOPS Oper. Syst. Rev.},
	year = {2015},
	month = jan,
	volume = {49},
	number = {1},
	pages = {71--79},
	doi = {10.1145/2723872.2723882},
	url = {https://doi.org/10.1145/2723872.2723882},
	issn = {0163-5980},
	abstract = {As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.},
	urldate = {2025-09-03},
	keywords = {stats; reproducibility}
}

@article{goodchild1993,
	author = {Goodchild, M F and Anselin, L and Deichmann, U},
	title = {A {Framework} for the {Areal} {Interpolation} of {Socioeconomic} {Data}},
	journal = {Environment and Planning A: Economy and Space},
	year = {1993},
	month = mar,
	volume = {25},
	number = {3},
	pages = {383--397},
	doi = {10.1068/a250383},
	url = {https://doi.org/10.1068/a250383},
	issn = {0308-518X},
	abstract = {Spatial data are collected and represented as attributes of spatial objects embedded in a plane. Basis change is defined as the transfer of attributes from one set of objects to another. Methods of basis change for socioeconomic data are reviewed and are seen to differ in the assumptions made in each about underlying density surfaces. These methods are extended to more general cases, and an illustration is provided by using Californian data. The implementation of this framework within a geographical information system is discussed.},
	language = {EN},
	urldate = {2025-09-03},
	note = {Publisher: SAGE Publications Ltd}
}

@misc{usgs2021,
	author = {USGS},
	title = {Protected {Areas} {Database} of the {United} {States} ({PAD}-{US}) 2.1 - {World} {Database} on {Protected} {Areas} ({WDPA}) {Submission} (ver 1.1, {April} 2021) {\textbar} {U}.{S}. {Geological} {Survey}},
	year = {2021},	
	url = {https://www.usgs.gov/data/protected-areas-database-united-states-pad-us-21-world-database-protected-areas-wdpa},
	urldate = {2025-09-03}
}

@article{karger2017,
	author = {Karger, Dirk Nikolaus and Conrad, Olaf and Böhner, Jürgen and Kawohl, Tobias and Kreft, Holger and Soria-Auza, Rodrigo Wilber and Zimmermann, Niklaus E. and Linder, H. Peter and Kessler, Michael},
	title = {Climatologies at high resolution for the earth’s land surface areas},
	journal = {Scientific Data},
	year = {2017},
	month = sep,
	volume = {4},
	number = {1},
	pages = {170122},
	doi = {10.1038/sdata.2017.122},
	url = {https://www.nature.com/articles/sdata2017122},
	issn = {2052-4463},
	copyright = {2017 The Author(s)},
	abstract = {High-resolution information on climatic conditions is essential to many applications in environmental and ecological sciences. Here we present the CHELSA (Climatologies at high resolution for the earth’s land surface areas) data of downscaled model output temperature and precipitation estimates of the ERA-Interim climatic reanalysis to a high resolution of 30 arc sec. The temperature algorithm is based on statistical downscaling of atmospheric temperatures. The precipitation algorithm incorporates orographic predictors including wind fields, valley exposition, and boundary layer height, with a subsequent bias correction. The resulting data consist of a monthly temperature and precipitation climatology for the years 1979–2013. We compare the data derived from the CHELSA algorithm with other standard gridded products and station data from the Global Historical Climate Network. We compare the performance of the new climatologies in species distribution modelling and show that we can increase the acc	uracy of species range predictions. We further show that CHELSA climatological data has a similar accuracy as other products for temperature, but that its predictions of precipitation patterns are better.},
	language = {en},
	urldate = {2025-09-03},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biogeography, Atmospheric science, Hydrology}
}

@article{ellis-soto_SI_2023,
	author = {Ellis-Soto, Diego and Chapman, Melissa and Locke, Dexter H.},
	title = {Bird biodiversity sampling shows increasing geographical disparities associated with historical redlining in the {United} {States}},
	year = {2023},
	month = jun,
	doi = {10.5281/zenodo.8052525},
	url = {https://zenodo.org/records/8052525},
	abstract = {Historic segregation and inequality are critical to understanding modern environmental conditions. Race-based zoning policies, such as redlining in the United States during the 1930s, are associated with racial inequity and adverse multigenerational socioeconomic levels in income and education, and disparate environmental characteristics including tree canopy cover across urban neighborhoods. We quantify the association between redlining and bird biodiversity sampling density and completeness - two critical metrics of biodiversity knowledge - across 195 cities in the United States. We show that historically redlined neighborhoods remain the most under-sampled urban areas for bird biodiversity today, potentially impacting conservation priorities and propagating urban environmental inequities. The disparity in sampling across redlined neighborhoods grades increased by approximately 40\% over the past 20 years. We identify specific areas critical for reducing uncertainty and increasing equity of sampling of biodiversity in urban areas. Our findings highlight how human behavior and past social, economic and political conditions segregate not just our built environment, but may also leave a lasting mark also the on the digital information we have about urban biodiversity.


Methodology: 


The Global Biodiversity Information Facility (https://gbif.org) provided us with georeferenced biodiversity records for bird species found inside HOLC-defined neighborhoods in 195 cities. We searched for and downloaded bird recordings with geographic coordinates that were gathered after 1932 up to October 2022 using the rgbif package. The terms "observation," "live specimen," "human observation," "preserved specimen," and "machine observation" were all used to describe the recordings we compiled.


Please see the README\_data.md for description on the biodiversity data and the README\_code.md for a description on the code used in this manuscript. For additional questions feel free to reach out to diego.ellissoto@yale.edu},
	urldate = {2025-10-07},
	keywords = {Urban ecology, Biodiversity, Environmental Justice, Redlining}
}

@article{editorial2024,
	author = {Editorial},
	title = {Promoting reproduction and replication at scale},
	journal = {Nature Human Behaviour},
	year = {2024},
	month = jan,
	volume = {8},
	number = {1},
	pages = {1--1},
	doi = {10.1038/s41562-024-01818-7},
	url = {https://www.nature.com/articles/s41562-024-01818-7},
	issn = {2397-3374},
	copyright = {2024 Springer Nature Limited},
	abstract = {Nature Human Behaviour is partnering with the Institute for Replication for the large-scale reproduction and replication of our published research.},
	language = {en},
	urldate = {2025-10-07},
	note = {Publisher: Nature Publishing Group},
	keywords = {Behavioral Sciences, Experimental Psychology, general, Life Sciences, Microeconomics, Neurosciences, Personality and Social Psychology}
}

@article{zuur2010,
	author = {Zuur, Alain F. and Ieno, Elena N. and Elphick, Chris S.},
	title = {A protocol for data exploration to avoid common statistical problems},
	journal = {Methods in Ecology and Evolution},
	year = {2010},
	volume = {1},
	number = {1},
	pages = {3--14},
	doi = {10.1111/j.2041-210X.2009.00001.x},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2041-210X.2009.00001.x},
	issn = {2041-210X},
	copyright = {© 2009 The Authors. Journal compilation © 2009 British Ecological Society},
	abstract = {1. While teaching statistics to ecologists, the lead authors of this paper have noticed common statistical problems. If a random sample of their work (including scientific papers) produced before doing these courses were selected, half would probably contain violations of the underlying assumptions of the statistical techniques employed. 2. Some violations have little impact on the results or ecological conclusions; yet others increase type I or type II errors, potentially resulting in wrong ecological conclusions. Most of these violations can be avoided by applying better data exploration. These problems are especially troublesome in applied ecology, where management and policy decisions are often at stake. 3. Here, we provide a protocol for data exploration; discuss current tools to detect outliers, heterogeneity of variance, collinearity, dependence of observations, problems with interactions, double zeros in multivariate analysis, zero inflation in generalized linear modelling, and the correct type of relationships between dependent and independent variables; and provide advice on how to address these problems when they arise. We also address misconceptions about normality, and provide advice on data transformations. 4. Data exploration avoids type I and type II errors, among other problems, thereby reducing the chance of making wrong ecological conclusions and poor recommendations. It is therefore essential for good quality management and policy based on statistical analyses.},
	language = {en},
	urldate = {2025-11-13},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2041-210X.2009.00001.x},
	keywords = {collinearity, data exploration, independence, transformations, type I and II errors, zero inflation}
}

@article{ives2021,
	author = {Ives, Anthony R. and Zhu, Likai and Wang, Fangfang and Zhu, Jun and Morrow, Clay J. and Radeloff, Volker C.},
	title = {Statistical inference for trends in spatiotemporal data},
	journal = {Remote Sensing of Environment},
	year = {2021},
	month = dec,
	volume = {266},
	pages = {112678},
	doi = {10.1016/j.rse.2021.112678},
	url = {https://www.sciencedirect.com/science/article/pii/S0034425721003989},
	issn = {0034-4257},
	abstract = {Global change analyses are facilitated by the growing number of remote-sensing datasets that have both broad spatial extent and repeated observations over decades. These datasets provide unprecedented power to detect patterns of time trends involving information from all pixels on a map. However, rigorously testing for time trends requires a solid statistical foundation to identify underlying patterns and test hypotheses. Appropriate statistical analyses are challenging because environmental data often have temporal and spatial autocorrelation, which can either obscure underlying patterns in the data or suggest false associations between patterns in the data and independent values used to explain them. Existing statistical methods that account for temporal and spatial autocorrelation are not practical for remote-sensing datasets that often contain millions of pixels. Here, we first analyze simulated data to show the need to account for both spatial and temporal autocorrelation in time-trend analyses. Second, we present a new statistical approach, PARTS (Partitioned Autoregressive Time Series), to identify underlying patterns and test hypotheses about time trends using all pixels in large remote-sensing datasets. PARTS is flexible and can include, for example, the effects of multiple independent variables, such as land-cover or latitude, on time trends. Third, we use PARTS to analyze global trends in NDVI, focusing on trends in pixels that have not experienced land-cover change. We found that despite the appearance of overall increases in NDVI in all continents, there is little statistical support for these trends except for Asia and Europe, and only in some land-cover classes. Furthermore, we found no overall latitudinal trend in greening for any continent, but some latitude by land-cover class interactions, implying that latitudinal patterns differed among land-cover classes. PARTS makes it possible to identify patterns and test hypotheses that involve the aggregate information from many pixels on a map, thereby increasing the value of existing remote-sensing datasets.},
	urldate = {2025-11-13},
	keywords = {Global patterns in temporal trends, Large datasets, Spatial autocorrelation, Spatiotemporal analysis, Statistical hypothesis testing, Temporal autocorrelation}
}

@article{knief2021,
	author = {Knief, Ulrich and Forstmeier, Wolfgang},
	title = {Violating the normality assumption may be the lesser of two evils},
	journal = {Behavior Research Methods},
	year = {2021},
	month = dec,
	volume = {53},
	number = {6},
	pages = {2576--2590},
	doi = {10.3758/s13428-021-01587-5},
	url = {https://doi.org/10.3758/s13428-021-01587-5},
	issn = {1554-3528},
	abstract = {When data are not normally distributed, researchers are often uncertain whether it is legitimate to use tests that assume Gaussian errors, or whether one has to either model a more specific error structure or use randomization techniques. Here we use Monte Carlo simulations to explore the pros and cons of fitting Gaussian models to non-normal data in terms of risk of type I error, power and utility for parameter estimation. We find that Gaussian models are robust to non-normality over a wide range of conditions, meaning that p values remain fairly reliable except for data with influential outliers judged at strict alpha levels. Gaussian models also performed well in terms of power across all simulated scenarios. Parameter estimates were mostly unbiased and precise except if sample sizes were small or the distribution of the predictor was highly skewed. Transformation of data before analysis is often advisable and visual inspection for outliers and heteroscedasticity is important for assessment. In strong contrast, some non-Gaussian models and randomization techniques bear a range of risks that are often insufficiently known. High rates of false-positive conclusions can arise for instance when overdispersion in count data is not controlled appropriately or when randomization procedures ignore existing non-independencies in the data. Hence, newly developed statistical methods not only bring new opportunities, but they can also pose new threats to reliability. We argue that violating the normality assumption bears risks that are limited and manageable, while several more sophisticated approaches are relatively error prone and particularly difficult to check during peer review. Scientists and reviewers who are not fully aware of the risks might benefit from preferentially trusting Gaussian mixed models in which random effects account for non-independencies in the data.},
	language = {en},
	number = {6},
	urldate = {2025-11-13},
	keywords = {Hypothesis testing, Linear model, Normality, Regression}
	}

@article{vaida2005,
	author = {Vaida, Florin and Blanchard, Suzette},
	title = {Conditional {Akaike} {Information} for {Mixed}-{Effects} {Models}},
	journal = {Biometrika},
	year = {2005},
	volume = {92},
	number = {2},
	pages = {351--370},
	url = {https://www.jstor.org/stable/20441193},
	issn = {0006-3444},
	abstract = {This paper focuses on the Akaike information criterion, AIC, for linear mixed-effects models in the analysis of clustered data. We make the distinction between questions regarding the population and questions regarding the particular clusters in the data. We show that the AIC in current use is not appropriate for the focus on clusters, and we propose instead the conditional Akaike information and its corresponding criterion, the conditional AIC, cAIC. The penalty term in cAIC is related to the effective degrees of freedom ρ for a linear mixed model proposed by Hodges \& Sargent (2001); ρ reflects an intermediate level of complexity between a fixed-effects model with no cluster effect and a corresponding model with fixed cluster effects. The cAIC is defined for both maximum likelihood and residual maximum likelihood estimation. A pharmacokinetics data application is used to illuminate the distinction between the two inference settings, and to illustrate the use of the conditional AIC in model selection.},
	urldate = {2025-11-13},
	note = {Publisher: [Oxford University Press, Biometrika Trust]}
}

@article{greven2010,
	author = {Greven, Sonja and Kneib, Thomas},
	title = {On the behaviour of marginal and conditional {AIC} in linear mixed models},
	journal = {Biometrika},
	year = {2010},
	volume = {97},
	number = {4},
	pages = {773--789},
	url = {https://www.jstor.org/stable/29777136},
	issn = {0006-3444},
	abstract = {In linear mixed models, model selection frequently includes the selection of random effects. Two versions of the Akaike information criterion, AIC, have been used, based either on the marginal or on the conditional distribution. We show that the marginal AIC is not an asymptotically unbiased estimator of the Akaike information, and favours smaller models without random effects. For the conditional AIC, we show that ignoring estimation uncertainty in the random effects covariance matrix, as is common practice, induces a bias that can lead to the selection of any random effect not predicted to be exactly zero. We derive an analytic representation of a corrected version of the conditional AIC, which avoids the high computational cost and imprecision of available numerical approximations. An implementation in an R package (R Development Core Team, 2010) is provided. All theoretical results are illustrated in simulation studies, and their impact in practice is investigated in an analysis of childhood malnutrition in Zambia.},
	urldate = {2025-11-13},
	note = {Publisher: [Oxford University Press, Biometrika Trust]}
}

@book{zuur2009,
	author = {Zuur, Alain F. and Ieno, Elena N. and Walker, Neil and Saveliev, Anatoly A. and Smith, Graham M.},
	title = {Mixed effects models and extensions in ecology with {R}},
	series = {Statistics for {Biology} and {Health}},
	year = {2009},
	publisher = {Springer},
	address = {New York, NY},
	doi = {10.1007/978-0-387-87458-6},
	isbn = {978-0-387-87457-9 978-0-387-87458-6},
	url = {https://link.springer.com/10.1007/978-0-387-87458-6},
	language = {en},
	urldate = {2025-11-13},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	keywords = {ecological analysis, ecological statistics, ecology, environment, GLM, mixed effects modeling, phytoplankton, plankton, R and ecology}
}